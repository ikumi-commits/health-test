
import os
import streamlit as st
import pickle
import numpy as np
import shap
import gdown
import pandas as pd
import google.generativeai as genai
import time
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pypdf import PdfReader



st.set_page_config(layout="wide")

#ã‚¿ã‚¤ãƒˆãƒ«
st.markdown("""
<h1 style="
    color: #2563eb;
    border-bottom: 3px solid #2563eb;
    padding-bottom: 0.3em;
    margin-bottom: 0.8em;
">
ç³–å°¿ç—…ãƒªã‚¹ã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
</h1>
""", unsafe_allow_html=True)


# session_state åˆæœŸåŒ–
if "predicted" not in st.session_state:
    st.session_state["predicted"] = False

if "prob" not in st.session_state:
    st.session_state["prob"] = None

if "suppress_factors" not in st.session_state:
    st.session_state["suppress_factors"] = []

if "increase_factors" not in st.session_state:
    st.session_state["increase_factors"] = []

if "intro_text" not in st.session_state:
    st.session_state["intro_text"] = ""

if "target_factors" not in st.session_state:
    st.session_state["target_factors"] = []


# åŒæ„çŠ¶æ…‹ã®åˆæœŸåŒ–
if "agreed" not in st.session_state:
    st.session_state["agreed"] = False


# åŒæ„ç”»é¢
if not st.session_state["agreed"]:
    st. write("#### â˜…ã”åˆ©ç”¨ã«ã‚ãŸã£ã¦ã®æ³¨æ„â˜…")

    st.markdown(
        "<small>1.æœ¬ã‚µã‚¤ãƒˆã¯ã€ç”Ÿæ´»ç¿’æ…£ã®æ”¹å–„ã«ã‚ˆã‚‹å¥åº·å¢—é€²ã‚’ç›®çš„ã¨ã—ãŸã‚‚ã®ã§ã‚ã‚Šã€"
        "ç–¾ç—…ã®è¨ºæ–­ãƒ»æ²»ç™‚ãƒ»äºˆé˜²ã‚’ç›®çš„ã¨ã—ãŸã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</small>",
        unsafe_allow_html=True
    )

    st.markdown(
        "<small>2.æœ¬ã‚µã‚¤ãƒˆã§è¡¨ç¤ºã•ã‚Œã‚‹äºˆæ¸¬å€¤ã¯ã€éå»ã®ãƒ‡ãƒ¼ã‚¿å‚¾å‘ã‚’ã‚‚ã¨ã«äºˆæ¸¬ã•ã‚Œã‚‹ã‚‚ã®ã§ã‚ã‚Šã€"
        "åŒ»å­¦çš„åˆ¤æ–­ã«ã‚ˆã‚Šäºˆæ¸¬ã‚’ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</small>",
        unsafe_allow_html=True
    )

    st.write("")  # ä½™ç™½

    if st.button("åŒæ„ã™ã‚‹"):
        st.session_state["agreed"] = True
        with st.spinner("ãŠå¾…ã¡ãã ã•ã„..."):
            time.sleep(2)
        st.rerun()

    # åŒæ„å‰ã¯ã“ã“ã§å‡¦ç†ã‚’æ­¢ã‚ã‚‹
    st.stop()



# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
FILE_ID = "1Mh7btoQb9QYpGg0KHhzIrpHhegG5ocq2"
MODEL_LOCAL_PATH = "rf_model.pkl"

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿é–¢æ•°
@st.cache_resource
def load_model():
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã° Google Drive ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if not os.path.exists(MODEL_LOCAL_PATH):
        url = f"https://drive.google.com/uc?id={FILE_ID}"
        gdown.download(url, MODEL_LOCAL_PATH, quiet=False)

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰èª­ã¿è¾¼ã‚€
    if os.path.exists(MODEL_LOCAL_PATH):
        with open(MODEL_LOCAL_PATH, "rb") as f:
            model = pickle.load(f)
        return model

    else:
        st.error("ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

# å®Ÿéš›ã«ãƒ­ãƒ¼ãƒ‰
model = load_model()

#ç‰¹å¾´é‡ã‚’èª­ã¿è¾¼ã¿
with open("feature_names.pkl", "rb") as f:
    feature_names = pickle.load(f)

feature_labels = {
    "HighBP": "é«˜è¡€åœ§",
    "HighChol": "é«˜ã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«",
    "CholCheck": "ã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«æ¤œæŸ»æ¸ˆã¿",
    "Smoker": "å–«ç…™ç¿’æ…£",
    "Stroke": "è„³å’ä¸­",
    "HeartDiseaseorAttack": "å¿ƒè‡“ç—…ãƒ»å¿ƒç­‹æ¢—å¡",
    "PhysActivity": "é‹å‹•ç¿’æ…£",
    "HvyAlcoholConsump": "é£²é…’ç¿’æ…£",
    "DiffWalk": "æ­©è¡Œã‚„éšæ®µæ˜‡é™ã®æ”¯éšœ",
    "Sex": "æ€§åˆ¥",
    "Age": "å¹´é½¢",
    "BMI": "BMI",
    "GenHlth": "ä¸»è¦³çš„ãªå¥åº·çŠ¶æ…‹",
    "PhysHlth": "èº«ä½“ã®ä¸èª¿æ—¥æ•°ï¼ˆéå»30æ—¥ï¼‰",
    "MentHlth": "ãƒ¡ãƒ³ã‚¿ãƒ«ã®ä¸èª¿æ—¥æ•°ï¼ˆéå»30æ—¥ï¼‰",
    "Income": "æ‰€å¾—",
    "Fruits": "æœç‰©æ‘‚å–ç¿’æ…£ï¼ˆï¼‘æ—¥ã«ï¼‘å›ä»¥ä¸Šé£Ÿã¹ã‚‹ï¼‰",
    "Veggies": "é‡èœæ‘‚å–ï¼ˆï¼‘æ—¥ã«ï¼‘å›ä»¥ä¸Šé£Ÿã¹ã‚‹ï¼‰"
}

#å¹´é½¢ã‚«ãƒ†ã‚´ãƒª
age_options = {
    1: "18ï½24æ­³",
    2: "25ï½29æ­³",
    3: "30ï½34æ­³",
    4: "35ï½39æ­³",
    5: "40ï½44æ­³",
    6: "45ï½49æ­³",
    7: "50ï½54æ­³",
    8: "55ï½59æ­³",
    9: "60ï½64æ­³",
    10: "65ï½69æ­³",
    11: "70ï½74æ­³",
    12: "75ï½79æ­³",
    13: "80æ­³ä»¥ä¸Š"
}

# æ‰€å¾—ã‚«ãƒ†ã‚´ãƒªï¼ˆå††æ›ç®—ï¼‰
income_options = {
    1: "ã€œ150ä¸‡å††æœªæº€",
    2: "150ã€œ300ä¸‡å††æœªæº€",
    3: "300ã€œ375ä¸‡å††æœªæº€",
    4: "375ã€œ525ä¸‡å††æœªæº€",
    5: "525ã€œ675ä¸‡å††æœªæº€",
    6: "675ã€œ900ä¸‡å††æœªæº€",
    7: "900ã€œ1125ä¸‡å††æœªæº€",
    8: "1125ä¸‡å††ä»¥ä¸Š"
}

# ä¸»è¦³çš„å¥åº·çŠ¶æ…‹
genhlth_options = {
            1: "éå¸¸ã«è‰¯ã„",
            2: "ã¨ã¦ã‚‚è‰¯ã„",
            3: "è‰¯ã„",
            4: "æ™®é€š",
            5: "æ‚ªã„"
        }


ordered_features = ["Sex", "Age", "BMI","Stroke","HeartDiseaseorAttack"] + [f for f in feature_names if f not in ["Sex", "Age", "BMI","Stroke","CholCheck","HeartDiseaseorAttack","AnyHealthcare","NoDocbcCost"]]
inputs = {}

#å‰æèª¬æ˜
st.markdown("#### ğŸ§¾ ã“ã®ã‚¢ãƒ—ãƒªã§ã‚ã‹ã‚‹ã“ã¨")
st.markdown(
    "- ã‚ãªãŸã¨ä¼¼ãŸçŠ¶æ…‹ã®æ–¹ãŒç³–å°¿ç—…ã‚’ç™ºç—‡ã—ãŸå‰²åˆ\n"
    "- ç™ºç—‡ãƒªã‚¹ã‚¯ã¨é–¢ä¿‚ãŒã‚ã‚‹ç¾åœ¨ã®ç”Ÿæ´»ç¿’æ…£\n"
    "- ä»Šå¾Œã«å‘ã‘ãŸç”Ÿæ´»ã®ãƒ’ãƒ³ãƒˆ"
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ä½œæˆ
def load_css():
    st.markdown("""
    <style>
    div[data-testid="stFormSubmitButton"] button {
        background-color: #27ae60;  /* æ¿ƒã„ç·‘ */
        color: white;               /* æ–‡å­—ã‚’ç™½ */
        border: none;
    }
    div[data-testid="stFormSubmitButton"] button:hover {
        background-color: #1e8449;  /* ãƒ›ãƒãƒ¼æ™‚ã•ã‚‰ã«æ¿ƒã */
        color: white;
    }
    </style>
    """, unsafe_allow_html=True)

load_css()

basic_features = [
    "Sex", "Age", "BMI", "Income"
]

history_features = [
    "HighBP",
    "HighChol",
    "Stroke",
    "HeartDiseaseorAttack"
]

lifestyle_features = [
    f for f in ordered_features
    if f not in basic_features + history_features
]

with st.form("input_form"):

    # =====================
    # ğŸ‘¤ åŸºæœ¬æƒ…å ±
    # =====================
    st.markdown("### ğŸ‘¤ åŸºæœ¬æƒ…å ±")
    col1, col2 = st.columns(2)

    for i, feature in enumerate(basic_features):
        label = feature_labels.get(feature, feature)
        col = col1 if i % 2 == 0 else col2

        with col:
            if feature == "Sex":
                choice = st.selectbox(label, ["å¥³æ€§", "ç”·æ€§"])
                inputs[feature] = 0 if choice == "å¥³æ€§" else 1

            elif feature == "Age":
                choice = st.selectbox(label, list(age_options.values()))
                inputs[feature] = [k for k, v in age_options.items() if v == choice][0]

            elif feature == "Income":
                choice = st.selectbox(label, list(income_options.values()))
                inputs[feature] = list(income_options.keys())[list(income_options.values()).index(choice)]

            else:
                inputs[feature] = st.number_input(label, min_value=0.0, step=1.0)

    # =====================
    # ğŸ¥ æ—¢å¾€æ­´
    # =====================
    st.markdown("### ğŸ¥ æ—¢å¾€æ­´")
    col1, col2 = st.columns(2)

    for i, feature in enumerate(history_features):
        label = feature_labels.get(feature, feature)
        col = col1 if i % 2 == 0 else col2

        with col:
            choice = st.selectbox(label, ["ã„ã„ãˆ", "ã¯ã„"])
            inputs[feature] = 0 if choice == "ã„ã„ãˆ" else 1

    # =====================
    # ğŸƒ ç”Ÿæ´»ç¿’æ…£
    # =====================
    st.markdown("### ğŸƒ ç”Ÿæ´»ç¿’æ…£")
    col1, col2 = st.columns(2)

    for i, feature in enumerate(lifestyle_features):
        label = feature_labels.get(feature, feature)
        col = col1 if i % 2 == 0 else col2

        with col:
            if feature == "GenHlth":
                choice = st.selectbox(label, list(genhlth_options.values()))
                inputs[feature] = list(genhlth_options.keys())[list(genhlth_options.values()).index(choice)]

            elif feature == "MentHlth":
                inputs[feature] = st.selectbox(label, list(range(0, 31)))

            elif feature == "PhysHlth":
                inputs[feature] = st.selectbox(label, list(range(0, 31)))

            elif feature in [
                "Smoker","PhysActivity","HvyAlcoholConsump",
                "DiffWalk","Fruits","Veggies"
            ]:
                choice = st.selectbox(label, ["ã„ã„ãˆ", "ã¯ã„"])
                inputs[feature] = 0 if choice == "ã„ã„ãˆ" else 1

            else:
                inputs[feature] = st.number_input(label, min_value=0.0, step=1.0)

    submitted = st.form_submit_button(
        "ç³–å°¿ç—…ãƒªã‚¹ã‚¯ã‚’ç¢ºèªã™ã‚‹",
        use_container_width=True
    )


#ãƒªã‚¹ã‚¯ç®—å‡º
if submitted:
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­ã§ã™..."):
        time.sleep(2)

        inputs["CholCheck"] = 1
        inputs["AnyHealthcare"] = 1
        inputs["NoDocbcCost"] = 0

        x = np.array([inputs[f] for f in feature_names]).reshape(1, -1)

        prob = model.predict_proba(x)[0][1]

        # SHAPè¨ˆç®—ï¼ˆå½±éŸ¿ãŒå¤§ãã„ç‰¹å¾´é‡æŠ½å‡ºï¼‰
        explainer = shap.TreeExplainer(model)
        shap_result = explainer(x)
        values = np.array(shap_result.values)

        if values.ndim == 3:
            shap_vals = values[0, :, 1]
        else:
            shap_vals = values[0]

        df_shap = pd.DataFrame({
            "feature": feature_names,
            "impact": shap_vals
        })

        #è¡Œå‹•ã§ã¯å¤‰ãˆã‚‰ã‚Œãªã„ç‰¹å¾´é‡ã¯é™¤ã
        exclude_features = ["Age", "Sex", "Income"]
        df_shap = df_shap[~df_shap["feature"].isin(exclude_features)]
        df_shap = df_shap.sort_values("impact", key=np.abs, ascending=False)

        suppress_factors = []
        increase_factors = []

        for _, row in df_shap.head(3).iterrows():
            label = feature_labels.get(row["feature"], row["feature"])
            if row["impact"] < 0:
                suppress_factors.append(label)
            else:
                increase_factors.append(label)

        # session_state ã«ä¿å­˜
        st.session_state["predicted"] = True
        st.session_state["prob"] = prob
        st.session_state["suppress_factors"] = suppress_factors
        st.session_state["increase_factors"] = increase_factors

#ãƒªã‚¹ã‚¯ã®çŠ¶æ³ã«å¿œã˜ã¦ã€ãƒªã‚¹ã‚¯ã‚’æŠ¼ã—ä¸‹ã’ã¦ã„ã‚‹ã€æŠ¼ã—ä¸Šã’ã¦ã„ã‚‹ç‰¹å¾´é‡ã‚’ç‰¹å®šã™ã‚‹
if st.session_state["predicted"] and st.session_state["prob"] is not None:
    prob = st.session_state["prob"]
    suppress_factors = st.session_state["suppress_factors"]
    increase_factors = st.session_state["increase_factors"]

    # ---- ãƒªã‚¹ã‚¯åˆ†é¡ ----
    st.write("")
    st.write("")
    st.markdown("### ğŸ“Š åˆ¤å®šçµæœ")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.metric(
            label="ç³–å°¿ç—…ç™ºç—‡ãƒªã‚¹ã‚¯",
            value=f"{prob*100:.1f}ï¼…"
        )

    with col2:
        if prob < 0.10:
            st.success("ğŸŸ¢ ç³–å°¿ç—…ãƒªã‚¹ã‚¯ã¯ä½ã‚ã§ã™")
        elif prob < 0.30:
            st.warning("ğŸŸ¡ ç³–å°¿ç—…ãƒªã‚¹ã‚¯ãŒã‚„ã‚„é«˜ã‚ã§ã™")
        else:
            st.error("ğŸ”´ ç³–å°¿ç—…ãƒªã‚¹ã‚¯ãŒé«˜ã‚ã§ã™")

    st.caption("â€» éå»ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€åŒã˜çŠ¶æ…‹ã®æ–¹ãŒç³–å°¿ç—…ã‚’ç™ºç—‡ã—ã¦ã„ã‚‹ç¢ºç‡ã§ã™")


    # --------------------
    # ãƒªã‚¹ã‚¯è¦å› ã®è¡¨ç¤ºï¼ˆãƒã‚¤ãƒªã‚¹ã‚¯ã€ãƒ­ãƒ¼ãƒªã‚¹ã‚¯ã§è¡¨ç¤ºã‚’å‡ºã—åˆ†ã‘ã‚‹ï¼‰
    # --------------------
    def load_css_life():
        st.markdown("""
        <style>
        .tag-container {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 8px;
            margin-bottom: 8px;
        }

        .tag {
            display: inline-block;
            background-color: #eaf2fb;   /* æ·¡ã„é’ */
            color: #1f4fd8;              /* é’æ–‡å­— */
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 14px;
            line-height: 1.2;
            white-space: nowrap;
        }
        </style>
        """, unsafe_allow_html=True)


    load_css_life()

    st.markdown("### ğŸ” é–¢ä¿‚ã—ã¦ã„ã‚‹ç”Ÿæ´»ç¿’æ…£")

    with st.container():

        if prob < 0.10 and suppress_factors:

            #ãƒ­ãƒ¼ãƒªã‚¹ã‚¯
            tags_html = "".join(
                [f'<span class="tag">{factor}</span>' for factor in suppress_factors]
            )

            st.markdown(
                f"""
                <div style="border:1px solid rgba(0,0,0,0.1); padding:1em; border-radius:6px;">
                    <div class="tag-container">
                        {tags_html}
                    </div>
                    <p>
                        ã“ã‚Œã‚‰ã¯ã€ç³–å°¿ç—…ãƒªã‚¹ã‚¯ã‚’ä½ã‚ã«ä¿ã¤ã“ã¨ã«é–¢ä¿‚ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹è¦å› ã§ã™ã€‚<br>
                        ä»Šå¾Œã‚‚çŠ¶æ…‹ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã§ã€ç¾åœ¨ã®è©•ä¾¡ãŒä¿ã¤ã“ã¨ãŒã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
                    </p>
                </div>
                """,
                unsafe_allow_html=True
            )

        elif prob >= 0.10 and increase_factors:

            #ãƒã‚¤ãƒªã‚¹ã‚¯
            tags_html = "".join(
                [f'<span class="tag">{factor}</span>' for factor in increase_factors]
            )

            st.markdown(
                f"""
                <div style="border:1px solid rgba(0,0,0,0.1); padding:1em; border-radius:6px;">
                    <div class="tag-container">
                        {tags_html}
                    </div>
                    <p>
                        ã“ã‚Œã‚‰ã¯ã€ç³–å°¿ç—…ãƒªã‚¹ã‚¯ã«é–¢ä¿‚ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹è¦å› ã§ã™ã€‚<br>
                        çŠ¶æ…‹ã‚’è¦‹ç›´ã™ã“ã¨ã§ã€ç¾åœ¨ã®è©•ä¾¡ãŒå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
                    </p>
                </div>
                """,
                unsafe_allow_html=True
            )


    #ãƒªã‚¹ã‚¯ã«åŸºã¥ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å®šç¾©
    if prob < 0.10:
        target_factors = suppress_factors
        advice_mode = "maintain"
        intro_text = (
            "ç¾åœ¨ã®ç”Ÿæ´»ç¿’æ…£ã§ã€ç³–å°¿ç—…ãƒªã‚¹ã‚¯ã¯ä½ã‚ã«ä¿ãŸã‚Œã¦ã„ã¾ã™ã€‚"
            "ä»Šã®ç”Ÿæ´»ã‚’ç¶šã‘ã‚‹ãŸã‚ã®ãƒ’ãƒ³ãƒˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
        )
    else:
        target_factors = increase_factors
        advice_mode = "improve"
        intro_text = (
            "ç³–å°¿ç—…ãƒªã‚¹ã‚¯ãŒé«˜ã„çŠ¶æ…‹ã§ã™ã€‚é–¢ä¿‚ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ç”Ÿæ´»ç¿’æ…£ã«ã¤ã„ã¦ã€"
            "æ”¹å–„ã®ãƒ’ãƒ³ãƒˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
        )

    st.session_state["intro_text"] = intro_text
    st.session_state["target_factors"] = target_factors


    # --------------------
    # Geminiè¨­å®š
    # --------------------
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    genai_model = genai.GenerativeModel("gemini-2.5-flash")
    
    st.markdown("---")
    st.markdown("### ğŸ’¡çµæœã‚’ã‚‚ã¨ã«ã€ç”Ÿæ´»ã®ãƒ’ãƒ³ãƒˆã‚’ç¢ºèªã§ãã¾ã™")


#PDFèª­ã¿è¾¼ã¿
pdf_path = "tokyo-advice.pdf"

import pdfplumber

@st.cache_data
def load_pdf_pages(pdf_path):
    pages = []
    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages, start=1):
            text = page.extract_text()
            if text:
                pages.append({
                    "text": text,
                    "page": i,
                    "source": pdf_path
                })
    return pages

#PDFã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ã®æº–å‚™
def split_text_with_meta(pages, chunk_size=500, overlap=100):
    chunks = []
    for p in pages:
        text = p["text"]
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunks.append({
                "text": text[start:end],
                "page": p["page"],
                "source": p["source"]
            })
            start = end - overlap
    return chunks

@st.cache_data
def prepare_vectorstore(pdf_path):
    pages = load_pdf_pages(pdf_path)
    chunks = split_text_with_meta(pages)
    model = SentenceTransformer("all-MiniLM-L6-v2")
    embeddings = model.encode([c["text"] for c in chunks])
    return embeddings, chunks, model

embeddings, chunks, embed_model = prepare_vectorstore(pdf_path)

def retrieve_context(query, embeddings, chunks, model, top_k=3):
    query_vec = model.encode([query])
    sims = cosine_similarity(query_vec, embeddings)[0]
    top_indices = sims.argsort()[-top_k:][::-1]
    results = []
    for i in top_indices:
        results.append({
            "text": chunks[i]["text"],
            "page": chunks[i]["page"],
            "source": chunks[i]["source"],
            "score": sims[i]
        })
    return results

#RAGã‚’å®Ÿè¡Œã—ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç”Ÿæˆã™ã‚‹
#é–¢ä¿‚ã‚ã‚‹ç‰¹å¾´é‡ç­‰ã‚’è€ƒæ…®ã—ã¦å€‹åˆ¥æœ€é©åŒ–ã•ã‚ŒãŸå†…å®¹ã‚’è¡¨ç¤º
if st.session_state.get("predicted", False):

    if st.button("ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¦‹ã‚‹", use_container_width=True):
        with st.spinner("ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ä½œæˆã—ã¦ã„ã¾ã™..."):
            time.sleep(1)

            query = f"""
            çŠ¶æ³: {st.session_state["intro_text"]}
            é–¢é€£è¦å› : {'ã€'.join(st.session_state["target_factors"])}
            """

            retrieved_results = retrieve_context(
                query,
                embeddings,
                chunks,
                embed_model
            )

            reference_text = "\n\n".join([
                f"ã€å‡ºå…¸ã€‘{r['source']} / p.{r['page']}\n{r['text']}"
                for r in retrieved_results
            ])

            prompt = f"""
ã“ã®ã‚¢ãƒ—ãƒªã¯å¯¾è±¡è€…ã®ç³–å°¿ç—…ãƒªã‚¹ã‚¯ã‚’äºˆæ¸¬ã—ã¦è¡¨ç¤ºã™ã‚‹ã‚‚ã®ã§ã™ã€‚
ã‚ãªãŸã¯å¯¾è±¡è€…ã®ãƒªã‚¹ã‚¯ã‚„çŠ¶æ³ã«åŸºã¥ãã€ä¿å¥å¸«ã®ç«‹å ´ã§ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã„ã¾ã™ã€‚

ã€å¯¾è±¡è€…ã®çŠ¶æ³ã€‘
{st.session_state["prob"]}
{st.session_state["intro_text"]}


ã€ãƒªã‚¹ã‚¯ã«é–¢ä¿‚ã™ã‚‹è¦å› ã€‘
ãƒ»{'ã€'.join(st.session_state["target_factors"])}

ã€æ¡ä»¶ã€‘
ãƒ»çµæœã«ã¤ã„ã¦ã®è¨€åŠã¯è¡Œã‚ãªã„
ãƒ»è¨ºæ–­ã‚„æ²»ç™‚ã®æŒ‡ç¤ºã¯è¡Œã‚ãªã„
ãƒ»æ—¥å¸¸ç”Ÿæ´»ã§ç„¡ç†ãªãå–ã‚Šå…¥ã‚Œã‚„ã™ã„è¡Œå‹•ã«é™å®šã™ã‚‹
ãƒ»å„è¡Œå‹•ã«ã¤ã„ã¦ã€è¡Œã£ãŸå ´åˆã«æœŸå¾…ã•ã‚Œã‚‹å¤‰åŒ–ã‚’å¿…ãšè¨˜è¼‰ã™ã‚‹
ãƒ»3å€‹ã®ç®‡æ¡æ›¸ãã§å‡ºåŠ›ã™ã‚‹
ãƒ»è¡Œå‹•æ¡ˆã¯å¤ªå­—ã§1æ–‡ã¨ã™ã‚‹
ãƒ»è¡Œå‹•æ¡ˆã®æ¬¡ã®è¡Œã§ã€ŒæœŸå¾…ã•ã‚Œã‚‹å¤‰åŒ–ï¼šã€ã‚’ä»˜ã‘ã¦è¨˜è¼‰ã™ã‚‹
ãƒ»å°‚é–€ç”¨èªã¯ä½¿ã‚ãªã„

ã€æ¡ä»¶ã€‘
    ãƒ»çµæœã«ã¤ã„ã¦ã®è¨€åŠã¯è¡Œã‚ãªã„
    ãƒ»è¨ºæ–­ã‚„æ²»ç™‚ã®æŒ‡ç¤ºã¯è¡Œã‚ãªã„
    ãƒ»æ—¥å¸¸ç”Ÿæ´»ã§ç„¡ç†ãªãå–ã‚Šå…¥ã‚Œã‚„ã™ã„è¡Œå‹•ã«é™å®šã™ã‚‹
    ãƒ»å„è¡Œå‹•ã«ã¤ã„ã¦ã€è¡Œã£ãŸå ´åˆã«æœŸå¾…ã•ã‚Œã‚‹å¤‰åŒ–ã‚’å¿…ãšè¨˜è¼‰ã™ã‚‹
    ãƒ»3å€‹ã®ç®‡æ¡æ›¸ãã§å‡ºåŠ›ã™ã‚‹
    ãƒ»è¡Œå‹•æ¡ˆã¯å¤ªå­—ã§1æ–‡ã¨ã™ã‚‹
    ãƒ»è¡Œå‹•æ¡ˆã®æ¬¡ã®è¡Œã§ã€ŒæœŸå¾…ã•ã‚Œã‚‹å¤‰åŒ–ï¼šã€ã‚’ä»˜ã‘ã¦è¨˜è¼‰ã™ã‚‹
    ãƒ»1æ–‡ã¯ç°¡æ½”ã§ã€å°‚é–€ç”¨èªã¯ä½¿ã‚ãªã„

    ã€å‡ºåŠ›å½¢å¼ã€‘
    ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å³å¯†ã«å®ˆã‚‹ã“ã¨ã€‚

    ãƒ»å‡ºåŠ›ã¯Markdownå½¢å¼ã¨ã™ã‚‹
    ãƒ»æœ€åˆã«1è¡Œã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹
    ãƒ»ãã®å¾Œã€å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§3ã¤å‡ºåŠ›ã™ã‚‹

    **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆ1æ–‡ï¼‰**

    - **è¡Œå‹•æ¡ˆï¼ˆ1æ–‡ï¼‰**  
    æœŸå¾…ã•ã‚Œã‚‹å¤‰åŒ–ï¼šâ—¯â—¯â—¯

    - **è¡Œå‹•æ¡ˆï¼ˆ1æ–‡ï¼‰**  
    æœŸå¾…ã•ã‚Œã‚‹å¤‰åŒ–ï¼šâ—¯â—¯â—¯

    - **è¡Œå‹•æ¡ˆï¼ˆ1æ–‡ï¼‰**  
    æœŸå¾…ã•ã‚Œã‚‹å¤‰åŒ–ï¼šâ—¯â—¯â—¯

    ã€å‚è€ƒè³‡æ–™ã€‘
    {reference_text}
    """

            response = genai_model.generate_content(prompt)

            with st.container():
                st.markdown(
                    f"""
                    <div style="border:1px solid rgba(0,0,0,0.1); padding:1em; border-radius:6px;">
                        {response.text}
                    </div>
                    """,
                    unsafe_allow_html=True
                )


            #å‚ç…§ã—ãŸéƒ¨åˆ†ã‚’è¡¨ç¤ºã™ã‚‹
            REFERENCE_TITLE = "ç³–å°¿ç—…ç™ºç—‡äºˆé˜²ã‚¬ã‚¤ãƒ‰ãƒ–ãƒƒã‚¯ã€Œä»Šæ—¥ã‹ã‚‰äºˆé˜²ï¼ç³–å°¿ç—…ã€"
            REFERENCE_URL = "https://www.hokeniryo1.metro.tokyo.lg.jp/kensui/tonyo/citizen/6leaflet.html"

            # ãƒšãƒ¼ã‚¸ç•ªå·ã®ã¿é‡è¤‡æ’é™¤ã—ã¦æ˜‡é †ã«ã™ã‚‹
            pages = sorted({r["page"] for r in retrieved_results})

            with st.expander("å‚ç…§ãƒšãƒ¼ã‚¸"):
                st.markdown(
                    f"**{REFERENCE_TITLE}** "
                    f"[è³‡æ–™ãƒªãƒ³ã‚¯]({REFERENCE_URL})"
                )
                st.markdown(
                    "å‚ç…§ãƒšãƒ¼ã‚¸ï¼š" + "ã€".join([f"p.{p}" for p in pages])
                )